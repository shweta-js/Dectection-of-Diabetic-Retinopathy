{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T05:26:17.128473Z","iopub.execute_input":"2023-04-17T05:26:17.129220Z","iopub.status.idle":"2023-04-17T05:26:21.219176Z","shell.execute_reply.started":"2023-04-17T05:26:17.129176Z","shell.execute_reply":"2023-04-17T05:26:21.217952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the data","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.utils import shuffle\nimport random\nfrom sklearn.model_selection import train_test_split\nSEED=42\ndf_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ndf_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n\nx = df_train['id_code']\ny = df_train['diagnosis']\n\nx, y = shuffle(x, y, random_state=SEED)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T05:35:02.634656Z","iopub.execute_input":"2023-04-17T05:35:02.635078Z","iopub.status.idle":"2023-04-17T05:35:02.653204Z","shell.execute_reply.started":"2023-04-17T05:35:02.635045Z","shell.execute_reply":"2023-04-17T05:35:02.651731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n                                                      stratify=y, random_state=SEED)\nprint(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\ntrain_y.hist()\nvalid_y.hist()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:15:38.857774Z","iopub.execute_input":"2023-04-17T06:15:38.858250Z","iopub.status.idle":"2023-04-17T06:15:39.234395Z","shell.execute_reply.started":"2023-04-17T06:15:38.858195Z","shell.execute_reply":"2023-04-17T06:15:39.233180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nIMG_SIZE = 256  # or any other integer value representing the desired image size\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:22:56.764294Z","iopub.execute_input":"2023-04-17T06:22:56.764704Z","iopub.status.idle":"2023-04-17T06:22:56.770177Z","shell.execute_reply.started":"2023-04-17T06:22:56.764670Z","shell.execute_reply":"2023-04-17T06:22:56.768753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\n        plt.imshow(image)\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:22:57.199686Z","iopub.execute_input":"2023-04-17T06:22:57.200119Z","iopub.status.idle":"2023-04-17T06:23:03.371223Z","shell.execute_reply.started":"2023-04-17T06:22:57.200079Z","shell.execute_reply":"2023-04-17T06:23:03.369824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image=cv2.addWeighted ( image, 0 , cv2.GaussianBlur( image , (0 ,0 ) , 10) ,-4 ,128)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:24:39.181195Z","iopub.execute_input":"2023-04-17T06:24:39.181721Z","iopub.status.idle":"2023-04-17T06:24:44.288738Z","shell.execute_reply.started":"2023-04-17T06:24:39.181678Z","shell.execute_reply":"2023-04-17T06:24:44.287422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128) # the trick is to add this line\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:25:12.842075Z","iopub.execute_input":"2023-04-17T06:25:12.842529Z","iopub.status.idle":"2023-04-17T06:25:19.390371Z","shell.execute_reply.started":"2023-04-17T06:25:12.842484Z","shell.execute_reply":"2023-04-17T06:25:19.389206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:27:17.309611Z","iopub.execute_input":"2023-04-17T06:27:17.310053Z","iopub.status.idle":"2023-04-17T06:27:17.321444Z","shell.execute_reply.started":"2023-04-17T06:27:17.310012Z","shell.execute_reply":"2023-04-17T06:27:17.319964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:27:20.590312Z","iopub.execute_input":"2023-04-17T06:27:20.591435Z","iopub.status.idle":"2023-04-17T06:27:20.597795Z","shell.execute_reply.started":"2023-04-17T06:27:20.591387Z","shell.execute_reply":"2023-04-17T06:27:20.596448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n## try circle crop\n\ndef circle_crop(img):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    \n    return img \n   \nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = circle_crop(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:32:58.839766Z","iopub.execute_input":"2023-04-17T06:32:58.840221Z","iopub.status.idle":"2023-04-17T06:32:58.926830Z","shell.execute_reply.started":"2023-04-17T06:32:58.840182Z","shell.execute_reply":"2023-04-17T06:32:58.924967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:38:41.032820Z","iopub.execute_input":"2023-04-17T06:38:41.034022Z","iopub.status.idle":"2023-04-17T06:38:41.040433Z","shell.execute_reply.started":"2023-04-17T06:38:41.033972Z","shell.execute_reply":"2023-04-17T06:38:41.039427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n%%time\n\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T06:38:59.125236Z","iopub.execute_input":"2023-04-17T06:38:59.126095Z","iopub.status.idle":"2023-04-17T06:39:14.113672Z","shell.execute_reply.started":"2023-04-17T06:38:59.126017Z","shell.execute_reply":"2023-04-17T06:39:14.111987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}